{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FWI in Azure project\n",
    "\n",
    "## Set-up AzureML resources\n",
    "\n",
    "This project ports devito (https://github.com/opesci/devito) into Azure and runs tutorial notebooks at:\n",
    "https://nbviewer.jupyter.org/github/opesci/devito/blob/master/examples/seismic/tutorials/\n",
    "\n",
    "\n",
    "\n",
    "In this notebook we setup AzureML resources. This notebook should be run once and will enable all subsequent notebooks.\n",
    "\n",
    "<a id='user_input_requiring_steps'></a>\n",
    "User input requiring steps:\n",
    " - [Fill in and save sensitive information](#dot_env_description)\n",
    " - [Azure login](#Azure_login) (may be required first time the notebook is run) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Machine Learning and Pipeline SDK-specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import shutil\n",
    "import urllib\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Linux-4.15.0-1060-azure-x86_64-with-debian-10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/workspace/examples/imaging/azureml_devito/notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)\n",
    "platform.platform()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create utilities file\n",
    "\n",
    "##### 1.1 Define utilities file (project_utils.py) path\n",
    "Utilities file created here has code for Azure resources access authorization, project configuration settings like directories and file names in __project_consts__ class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_file_name = 'project_utils'\n",
    "auxiliary_files_dir = os.path.join(*(['.', 'src']))\n",
    "\n",
    "\n",
    "utils_path_name = os.path.join(os.getcwd(), auxiliary_files_dir)\n",
    "utils_full_name = os.path.join(utils_path_name, os.path.join(*([utils_file_name+'.py'])))\n",
    "os.makedirs(utils_path_name, exist_ok=True)\n",
    "    \n",
    "def ls_l(a_dir):\n",
    "    return ([f for f in os.listdir(a_dir) if os.path.isfile(os.path.join(a_dir, f))]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2. Edit/create project_utils.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /workspace/examples/imaging/azureml_devito/notebooks/./src/project_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $utils_full_name\n",
    "\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core.authentication import AuthenticationException\n",
    "import dotenv, logging, pathlib, os\n",
    "\n",
    "\n",
    "#  credit Mathew Salvaris\n",
    "def get_auth(env_path):\n",
    "    \"\"\"Tries to get authorization info by first trying to get Service Principal info, then CLI, then interactive. \n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    crt_sp_pwd = os.environ.get(\"SP_PASSWORD\", None)\n",
    "    if crt_sp_pwd:\n",
    "        logger.debug(\"Trying to create Workspace with Service Principal\")\n",
    "        aml_sp_password = crt_sp_pwd\n",
    "        aml_sp_tennant_id = dotenv.get_key(env_path, 'SP_TENANT_ID')\n",
    "        aml_sp_username = dotenv.get_key(env_path, 'SP_APPLICATION_ID')\n",
    "        auth = ServicePrincipalAuthentication(\n",
    "            tenant_id=aml_sp_tennant_id,\n",
    "            username=aml_sp_username,\n",
    "            password=aml_sp_password,\n",
    "        )\n",
    "    else:\n",
    "        logger.debug(\"Trying to create Workspace with CLI Authentication\")\n",
    "        try:\n",
    "            auth = AzureCliAuthentication()\n",
    "            auth.get_authentication_header()\n",
    "        except AuthenticationException:\n",
    "            logger.debug(\"Trying to create Workspace with Interactive login\")\n",
    "            auth = InteractiveLoginAuthentication()\n",
    "\n",
    "    return auth  \n",
    "\n",
    "\n",
    "def set_dotenv_info(dotenv_file_path, env_dict):\n",
    "    \"\"\"Use dict loop to set multiple keys in dotenv file.\n",
    "    Minimal file error management.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    if bool(env_dict):\n",
    "        dotenv_file = pathlib.Path(dotenv_file_path)\n",
    "        if not dotenv_file.is_file():\n",
    "            logger.debug('dotenv file not found, will create \"{}\" using the sensitive info you provided.'.format(dotenv_file_path))\n",
    "            dotenv_file.touch()\n",
    "        else:\n",
    "            logger.debug('dotenv file \"{}\" found, will (over)write it with current sensitive info you provided.'.format(dotenv_file_path))\n",
    "            \n",
    "        for crt_key, crt_val in env_dict.items():\n",
    "            dotenv.set_key(dotenv_file_path, crt_key, crt_val)\n",
    "\n",
    "    else:\n",
    "       logger.debug(\\\n",
    "                    'Trying to save empty env_dict variable into {}, please set your sensitive info in a dictionary.'\\\n",
    "                    .format(dotenv_file_path)) \n",
    "        \n",
    "\n",
    "class project_consts(object):\n",
    "    \"\"\"Keep project's file names and directory structure in one place.\n",
    "    Minimal setattr error management.\n",
    "    \"\"\"\n",
    "    \n",
    "    AML_WORKSPACE_CONFIG_DIR = ['.', '..',  'not_shared']\n",
    "    AML_EXPERIMENT_DIR = ['.', '..',  'temp']\n",
    "    AML_WORKSPACE_CONFIG_FILE_NAME = 'aml_ws_config.json'\n",
    "    DOTENV_FILE_PATH = AML_WORKSPACE_CONFIG_DIR + ['general.env'] \n",
    "    DOCKER_DOTENV_FILE_PATH = AML_WORKSPACE_CONFIG_DIR + ['dockerhub.env'] \n",
    "\n",
    "    def __setattr__(self, *_):\n",
    "        raise TypeError\n",
    "\n",
    "        \n",
    "if __name__==\"__main__\":\n",
    "    \"\"\"Basic function/class tests.\n",
    "    \"\"\"\n",
    "    import sys, os\n",
    "    prj_consts = project_consts()\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level=logging.DEBUG) # Logging Levels: DEBUG\t10, NOTSET\t0\n",
    "    logger.debug('AML ws file = {}'.format(os.path.join(*([os.path.join(*(prj_consts.AML_WORKSPACE_CONFIG_DIR)),\n",
    "                                            prj_consts.AML_WORKSPACE_CONFIG_FILE_NAME]))))\n",
    "\n",
    "    crt_dotenv_file_path = os.path.join(*(prj_consts.DOTENV_FILE_PATH))\n",
    "    set_dotenv_info(crt_dotenv_file_path, {})\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3. Import utilities functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_path_to_sys_path(path_to_append):\n",
    "    if not (any(path_to_append in paths for paths in sys.path)):\n",
    "        sys.path.append(path_to_append)\n",
    "        \n",
    "paths_to_append = [os.path.join(os.getcwd(), auxiliary_files_dir)]\n",
    "[add_path_to_sys_path(crt_path) for crt_path in paths_to_append]\n",
    "\n",
    "\n",
    "import project_utils\n",
    "prj_consts = project_utils.project_consts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Set-up the AML SDK infrastructure\n",
    "\n",
    "* Create Azure resource group (rsg),  workspaces, \n",
    "* save sensitive info using [python-dotenv](https://github.com/theskumar/python-dotenv)  \n",
    "  \n",
    "Notebook repeateability notes:\n",
    "* The notebook tries to find and use an existing Azure resource group (rsg) defined by __crt_resource_group__. It creates a new one if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_info = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dot_env_description'></a>\n",
    "\n",
    "##### 2.1. Input here sensitive and configuration information\n",
    "[dotenv](https://github.com/theskumar/python-dotenv) is used to hide sensitive info, like Azure subscription name/ID. The serialized info needs to be manually input once.  \n",
    "  \n",
    "* REQUIRED ACTION for the 2 cells below: uncomment them, add the required info in first cell below, run both cells one. \n",
    "  The sensitive information will be packed in __sensitive_info__ dictionary variable, which that will then be saved in a following cell in an .env file (__dotenv_file_path__) that should likely be git ignored.   \n",
    "\n",
    "*  OPTIONAL STEP: After running once the two cells below to save __sensitive_info__ dictionary variable with your custom info, you can comment them and leave the __sensitive_info__ variable defined above as an empty python dictionary.  \n",
    "   \n",
    "   \n",
    "__Notes__:\n",
    "* An empty __sensitive_info__ dictionary is ignored by the __set_dotenv_info__ function defined above in project_utils.py . \n",
    "* The saved .env file will be used thereafter in each cell that starts with %dotenv. \n",
    "* The saved .env file contains user specific information and it shoulld __not__ be version-controlled in git.\n",
    "* If you would like to [use service principal authentication](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/manage-azureml-service/authentication-in-azureml/authentication-in-azure-ml.ipynb) make sure you provide the optional values as well (see get_auth function definition in project_utils.py file created above for details).\n",
    "\n",
    "[Back](#user_input_requiring_steps) to summary of user input requiring steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subscription_id = \"\"\n",
    "# resource_group = \"ghiordanfwirsg01\"\n",
    "# workspace_name = \"ghiordanfwiws\"\n",
    "# workspace_region = \"eastus2\"\n",
    "# gpu_cluster_name = \"gpuclstfwi02\"\n",
    "# gpucluster_admin_user_name = \"\"\n",
    "# gpucluster_admin_user_password = \"\"\n",
    "# docker_login = \"georgedockeraccount\"\n",
    "# docker_pwd = \"\"\n",
    "# experimentation_image_tag = \"fwi01_azureml\"\n",
    "# experimentation_image_version = \"sdk.v1.0.60\"\n",
    "# docker_container_mount_point = '/datadrive01/prj/DeepSeismic/fwi' # use project directory or a subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensitive_info = {\n",
    "# 'SUBSCRIPTION_ID':subscription_id,\n",
    "# 'RESOURCE_GROUP':resource_group, \n",
    "# 'WORKSPACE_NAME':workspace_name, \n",
    "# 'WORKSPACE_REGION':workspace_region,\n",
    "# 'GPU_CLUSTER_NAME':gpu_cluster_name,\n",
    "# 'GPU_CLUSTER_ADMIN_USER_NAME':gpucluster_admin_user_name,\n",
    "# 'GPU_CLUSTER_ADMIN_USER_PASSWORD':gpucluster_admin_user_password,\n",
    "# 'DOCKER_LOGIN':docker_login,\n",
    "# 'DOCKER_PWD':docker_pwd,\n",
    "# 'EXPERIMENTATION_IMAGE_TAG':experimentation_image_tag,\n",
    "# 'EXPERIMENTATION_IMAGE_VERSION':experimentation_image_version,\n",
    "# 'DOCKER_CONTAINER_MOUNT_POINT':docker_container_mount_point\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Save sensitive info\n",
    "An empty __sensitive_info__ variable will be ingored.  \n",
    "A non-empty __sensitive_info__ variable will overwrite info in an existing .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./../not_shared/general.env'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "dotenv_file_path = os.path.join(*(prj_consts.DOTENV_FILE_PATH)) \n",
    "os.makedirs(os.path.join(*(prj_consts.DOTENV_FILE_PATH[:-1])), exist_ok=True)\n",
    "\n",
    "# # show .env file path\n",
    "# !pwd\n",
    "dotenv_file_path\n",
    "\n",
    "#save your sensitive info\n",
    "project_utils.set_dotenv_info(dotenv_file_path, sensitive_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3. Use (load) saved sensitive info\n",
    "THis is how sensitive info will be retrieved in other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv $dotenv_file_path\n",
    "\n",
    "subscription_id = os.getenv('SUBSCRIPTION_ID')\n",
    "# # print a bit of subscription ID, to show dotenv file was found and loaded \n",
    "# subscription_id[:2]\n",
    "\n",
    "crt_resource_group  = os.getenv('RESOURCE_GROUP')\n",
    "crt_workspace_name = os.getenv('WORKSPACE_NAME')\n",
    "crt_workspace_region = os.getenv('WORKSPACE_REGION') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.  Access your workspace\n",
    "\n",
    "* In AML SDK we can get a ws in two ways:  \n",
    "    - via Workspace(subscription_id = ...)   \n",
    "    - via Workspace.from_config(path=some_file_path).   \n",
    "    \n",
    "For demo purposes, both ways are shown in this notebook.\n",
    "\n",
    "*  At first notebook run:\n",
    "    - the AML workspace ws is typically not found, so a new ws object is created and persisted on disk.\n",
    "    - If the ws has been created other ways (e.g. via Azure portal), it may be persisted on disk by calling ws1.write_config(...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_config_dir = os.path.join(*(prj_consts.AML_WORKSPACE_CONFIG_DIR))\n",
    "workspace_config_file = prj_consts.AML_WORKSPACE_CONFIG_FILE_NAME\n",
    "\n",
    "# # print debug info if needed     \n",
    "# workspace_config_dir    \n",
    "# ls_l(os.path.join(os.getcwd(), os.path.join(*([workspace_config_dir]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Azure_login'></a>\n",
    "###### Login into Azure may be required here\n",
    "[Back](#user_input_requiring_steps) to summary of user input requiring steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace configuration loading succeeded. \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ws1 = Workspace(\n",
    "        subscription_id = subscription_id, \n",
    "        resource_group = crt_resource_group, \n",
    "        workspace_name = crt_workspace_name,\n",
    "        auth=project_utils.get_auth(dotenv_file_path))\n",
    "    print(\"Workspace configuration loading succeeded. \")\n",
    "#     ws1.write_config(path=os.path.join(os.getcwd(), os.path.join(*([workspace_config_dir]))),\n",
    "#             file_name=workspace_config_file)\n",
    "    del ws1 # ws will be (re)created later using from_config() function\n",
    "except Exception as e :\n",
    "    print('Exception msg: {}'.format(str(e )))\n",
    "    print(\"Workspace not accessible. Will create a new workspace below\")\n",
    "    \n",
    "    workspace_region = crt_workspace_region\n",
    "\n",
    "    # Create the workspace using the specified parameters\n",
    "    ws2 = Workspace.create(name = crt_workspace_name,\n",
    "                          subscription_id = subscription_id,\n",
    "                          resource_group = crt_resource_group, \n",
    "                          location = workspace_region,\n",
    "                          create_resource_group = True,\n",
    "                          exist_ok = False)\n",
    "    ws2.get_details()\n",
    "\n",
    "    # persist the subscription id, resource group name, and workspace name in aml_config/config.json.\n",
    "    ws2.write_config(path=os.path.join(os.getcwd(), os.path.join(*([workspace_config_dir]))),\n",
    "            file_name=workspace_config_file)\n",
    "    \n",
    "    #Delete ws2 and use ws = Workspace.from_config() as shwon below to recover the ws, rather than rely on what we get from one time creation\n",
    "    del ws2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.5.  Demo access to created workspace\n",
    "\n",
    "From now on, even in other notebooks, the provisioned AML workspace will be accesible using Workspace.from_config() as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path arg is:\n",
    "#   - a file path which explictly lists aml_config subdir for function from_config() \n",
    "#   - a dir path with a silently added <<aml_config>> subdir for function write_config(). \n",
    "ws = Workspace.from_config(path=os.path.join(os.getcwd(), \n",
    "                                             os.path.join(*([workspace_config_dir, '.azureml', workspace_config_file]))))\n",
    "# # print debug info if needed\n",
    "# print(ws.name, ws.resource_group, ws.location, ws.subscription_id[0], sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.6.  Create compute cluster used in following notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpuclstfwi02'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_cluster_name = os.getenv('GPU_CLUSTER_NAME')\n",
    "gpu_cluster_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing gpu cluster\n"
     ]
    }
   ],
   "source": [
    "max_nodes_value = 3\n",
    "\n",
    "try:\n",
    "    gpu_cluster = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print(\"Found existing gpu cluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Could not find gpu cluster, please create one\")\n",
    "    \n",
    "#     # Specify the configuration for the new cluster, add admin_user_ssh_key='ssh-rsa ... ghiordan@microsoft.com' if needed\n",
    "#     compute_config = AmlCompute.provisioning_configuration(vm_size=\"Standard_NC12\",\n",
    "#                                                            min_nodes=0,\n",
    "#                                                            max_nodes=max_nodes_value,\n",
    "#                                                            admin_username=os.getenv('GPU_CLUSTER_ADMIN_USER_NAME'), \n",
    "#                                                            admin_user_password=os.getenv('GPU_CLUSTER_ADMIN_USER_NAME'))\n",
    "#     # Create the cluster with the specified name and configuration\n",
    "#     gpu_cluster = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
    "\n",
    "#     # Wait for the cluster to complete, show the output log\n",
    "#     gpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running 000_Setup_GeophysicsTutorial_FWI_Azure_devito!\n"
     ]
    }
   ],
   "source": [
    "print('Finished running 000_Setup_GeophysicsTutorial_FWI_Azure_devito!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
